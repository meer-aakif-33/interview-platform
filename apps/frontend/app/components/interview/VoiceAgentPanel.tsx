// apps/frontend/app/components/interview/VoiceAgentPanel.tsx
"use client";

import { Mic, MicOff, PhoneOff } from "lucide-react";
import { useRef, useState } from "react";
import {
  Room,
  RoomEvent,
  createLocalAudioTrack,
  ConnectionState,
} from "livekit-client";

interface Props {
  sessionId: string;
  onEnd: () => void;
  onPartialTranscript: (speaker: "AGENT" | "CANDIDATE", text: string) => void;
  onFinalTranscript: (speaker: "AGENT" | "CANDIDATE", text: string) => void;
}

export default function VoiceAgentPanel({
  sessionId,
  onEnd,
  onPartialTranscript,
  onFinalTranscript,
}: Props) {
  const roomRef = useRef<Room | null>(null);
  const [connected, setConnected] = useState(false);
  const [muted, setMuted] = useState(false);

const startCall = async () => {
  console.log("ðŸš€ Starting call for session:", sessionId);

  const res = await fetch("http://localhost:4000/api/livekit/token", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ sessionId, identity: "candidate" }),
  });
  const data = await res.json();
  console.log("LiveKit response:", data);

  const { token, url } = data;

  if (typeof token !== "string") {
    console.error("Invalid token type:", token);
    throw new Error("LiveKit token must be a string");
  }

  console.log("ðŸŽŸ Token parts:", token.split(".").length);
  console.log("ðŸŒ LiveKit URL:", url);

  const room = new Room({
    adaptiveStream: true,
    dynacast: true,
  });

  roomRef.current = room;

  // Connection lifecycle
  room.on(RoomEvent.ConnectionStateChanged, (state) => {
    console.log("ðŸ”Œ Connection state:", state);
  });

  room.on(RoomEvent.Disconnected, (reason) => {
    console.log("âŒ Disconnected from LiveKit:", reason);
  });

  room.on(RoomEvent.Reconnecting, () => {
    console.warn("âš ï¸ Reconnecting to LiveKit...");
  });

  room.on(RoomEvent.Reconnected, () => {
    console.log("âœ… Reconnected to LiveKit");
  });

  // ðŸ”Š AUDIO TRACK SUBSCRIPTION - ADD THIS
  room.on(RoomEvent.TrackSubscribed, (track, publication, participant) => {
    console.log("ðŸŽµ Track subscribed:", track.kind, "from", participant.identity);
    
    if (track.kind === "audio") {
      const audioElement = track.attach();
      document.body.appendChild(audioElement);
      console.log("ðŸ”Š Audio element attached and playing");
    }
  });

  room.on(RoomEvent.TrackPublished, (publication, participant) => {
    console.log("ðŸ“¢ Track published:", publication.kind, "from", participant.identity);
  });

  console.log("ðŸ”— Connecting to LiveKit...");
  await room.connect(url, token);
  console.log("âœ… Connected to LiveKit");

  console.log("ðŸŽ¤ Creating local mic track...");
  const micTrack = await createLocalAudioTrack();
  await room.localParticipant.publishTrack(micTrack);
  console.log("ðŸŽ™ Mic published");

  // Debug participants
  room.on(RoomEvent.ParticipantConnected, (p) => {
    console.log("ðŸ‘¤ Participant joined:", p.identity);
  });

  room.on(RoomEvent.ParticipantDisconnected, (p) => {
    console.log("ðŸ‘¤ Participant left:", p.identity);
  });

  // Debug data messages
  room.on(RoomEvent.DataReceived, (payload) => {
    const decoded = new TextDecoder().decode(payload);
    console.log("ðŸ“© Raw DataReceived:", decoded);

    const msg = JSON.parse(decoded);
    console.log("ðŸ“¨ Parsed message:", msg);

    if (msg.type === "transcript") {
      if (msg.final) {
        console.log("ðŸ§¾ Final transcript:", msg.text);
        onFinalTranscript(msg.speaker, msg.text);

        fetch(`http://localhost:4000/api/session/${sessionId}/transcript`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            speaker: msg.speaker,
            text: msg.text,
          }),
        }).then(() => console.log("ðŸ’¾ Transcript saved to backend"));
      } else {
        console.log("âœï¸ Partial transcript:", msg.text);
        onPartialTranscript(msg.speaker, msg.text);
      }
    }

    if (msg.type === "control" && msg.action === "INTERVIEW_ENDED") {
      console.warn("ðŸ›‘ Interview ended by agent");
      room.disconnect();
      setConnected(false);
      onEnd();
    }
  });

  setConnected(true);
  console.log("ðŸŸ¢ Call fully initialized");
};

  const toggleMute = () => {
    if (!roomRef.current) return;
    roomRef.current.localParticipant.setMicrophoneEnabled(muted);
    setMuted(!muted);
    console.log(muted ? "ðŸ”Š Mic unmuted" : "ðŸ”‡ Mic muted");
  };

  const endCall = async () => {
    console.warn("ðŸ›‘ Ending call manually");

    if (roomRef.current) {
      await roomRef.current.localParticipant.publishData(
        new TextEncoder().encode(
          JSON.stringify({ type: "control", action: "END_INTERVIEW" })
        ),
        { reliable: true }
      );

      console.log("ðŸ“¤ Sent END_INTERVIEW signal to agent");

      await roomRef.current.disconnect();
      roomRef.current = null;
    }

    setConnected(false);
    onEnd();
  };

  return (
    <div className="h-20 border-t flex items-center justify-center gap-6">
      {!connected ? (
        <button
          onClick={startCall}
          className="px-4 py-2 rounded bg-black text-white"
        >
          Start Call
        </button>
      ) : (
        <>
          <button onClick={toggleMute} className="p-3 rounded-full border">
            {muted ? <MicOff /> : <Mic />}
          </button>

          <button
            onClick={endCall}
            className="p-3 rounded-full bg-red-600 text-white"
          >
            <PhoneOff />
          </button>
        </>
      )}
    </div>
  );
}
